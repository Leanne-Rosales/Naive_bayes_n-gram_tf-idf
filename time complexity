import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix
import time

# Sample text data and labels (1 = Positive, 0 = Negative)
texts = [
    "I love machine learning",
    "Natural language processing is amazing",
    "I hate spam emails",
    "This algorithm is terrible",
    "The weather is great today",
    "I am learning data science",
    "Spam messages are annoying",
    "I enjoy solving problems with algorithms"
]
labels = [1, 1, 0, 0, 1, 1, 0, 1]  # 1 = Positive, 0 = Negative

# Step 1: Convert text to TF-IDF features (O(N * M))

start_time = time.time()
vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words='english', max_features=10)
X = vectorizer.fit_transform(texts)
end_time = time.time()

print("Feature names (n-grams):", vectorizer.get_feature_names_out())

print("Time Complexity of TF-IDF vectorization: O(N * M)")

print("Execution Time:", end_time - start_time, "seconds\n")

# Step 2: Split data into training and testing sets (O(N))
start_time = time.time()
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)
end_time = time.time()

print("Time Complexity of Train-Test Split: O(N)")

print("Execution Time:", end_time - start_time, "seconds\n")

# Step 3: Train Na√Øve Bayes classifier (O(N * M))
start_time = time.time()
model = MultinomialNB()
model.fit(X_train, y_train)
end_time = time.time()

print("Time Complexity of Model Training: O(N * M)")

print("Execution Time:", end_time - start_time, "seconds\n")

# Step 4: Prediction on test set (O(M))
start_time = time.time()
y_pred = model.predict(X_test)
end_time = time.time()

print("Time Complexity of Prediction: O(M)")

print("Execution Time:", end_time - start_time, "seconds\n")

# Step 5: Model Evaluation (O(N))
start_time = time.time()
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
end_time = time.time()

print("Time Complexity of Evaluation: O(N)")

print("Execution Time:", end_time - start_time, "seconds\n")

print("Accuracy:", accuracy)

print("Precision:", precision)

# Confusion Matrix Visualization (O(N))
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
